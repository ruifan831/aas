{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Backbone,RegionProposalNetwork,GeneralizedRCNN,ROIHead\n",
    "from data.dataset import VOCDataset,Transform\n",
    "from torch.utils.data import DataLoader\n",
    "from model.utils.anchor import AnchorGenerator\n",
    "from model.utils.creator_tool import ProposalTargetCreator,AnchorTargetGenerator\n",
    "from torchvision import transforms\n",
    "import matplotlib\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from trainer import FasterRCNNTrainer\n",
    "from train import train\n",
    "root=\"../VOCdevkit/VOC2007/\"\n",
    "# root = \"/home/ruifanxu/Desktop/ComputerVision/Faster_RCNN/VOCdevkit/VOC2007/\"\n",
    "trainData = VOCDataset(root,transform = Transform())\n",
    "loader = DataLoader(trainData,batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn = GeneralizedRCNN.FasterRCNN_vgg16(num_classes=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = FasterRCNNTrainer(rcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,classifier = Backbone.vggbackbone(True)\n",
    "rpnhead= RegionProposalNetwork.RPNHead(512,9)\n",
    "head = ROIHead.RoIHead(21,classifier,7,1/16)\n",
    "anGen = AnchorGenerator()\n",
    "anTargetGen = AnchorTargetGenerator()\n",
    "proposalTarget = ProposalTargetCreator()\n",
    "rpn = RegionProposalNetwork.RegionProposalNetwork(anGen,rpnhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_l1_loss(rpn_offset,offset,label):\n",
    "    in_weight = torch.zeros(offset.shape)\n",
    "    in_weight[(label>0).view(-1,1).expand_as(in_weight)]=1\n",
    "    differences = (offset-rpn_offset)*in_weight\n",
    "    abs_differences = differences.abs()\n",
    "    flag = (abs_differences<1).float()\n",
    "    y = flag*(abs_differences**2)+(1-flag)*(abs_differences-0.5)\n",
    "    return y.sum()/(label>=0).sum().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anGen.num_anchors_per_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(img,target) in enumerate(loader):\n",
    "#     result = rcnn(img)\n",
    "    result = rcnn.pred(img,[torch.tensor(target[\"origin_size\"]).numpy()])\n",
    "#     temp = model(img)\n",
    "    \n",
    "#     # after Region Proposal Network, calculate the rpn loss\n",
    "#     rpn_offset, rpn_score, rois,roi_indices,anchors=rpn(temp,img,1)\n",
    "#     offset,label = anTargetGen(target[\"boxes\"][0],anchors[0],img[0].shape[-2:])\n",
    "#     label = torch.from_numpy(label).long()\n",
    "#     offset = torch.from_numpy(offset)\n",
    "#     rpn_cls_loss = F.cross_entropy(rpn_score.view(-1,2),label,ignore_index=-1)\n",
    "#     rpn_offset_loss = smooth_l1_loss(rpn_offset.view(-1,4),offset,label)\n",
    "#     # ROI head loss.\n",
    "#     sample_roi, gt_roi_loc, gt_roi_label = proposalTarget(rois,target[\"boxes\"][0],target[\"labels\"][0])\n",
    "#     sample_roi_index= torch.zeros(len(sample_roi))\n",
    "#     roi_cls_loc,roi_score = head(temp,sample_roi,sample_roi_index)\n",
    "#     gt_roi_loc = torch.from_numpy(gt_roi_loc)\n",
    "#     roi_cls_loss = F.cross_entropy(roi_score,gt_roi_label)\n",
    "#     n_sample = gt_roi_loc.shape[0]\n",
    "#     roi_cls_loc = roi_cls_loc.view(n_sample,-1,4)\n",
    "#     roi_loc = roi_cls_loc[torch.arange(0, n_sample).long(),gt_roi_label]\n",
    "#     roi_cls_loss = smooth_l1_loss(roi_loc,gt_roi_loc,gt_roi_label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0][0][95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(result[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "plt.imshow(trans(img[0]))\n",
    "\n",
    "# Add the patch to the Axes\n",
    "plt.gca().add_patch(Rectangle((result[0][0][95][1],result[0][0][95][0]),result[0][0][95][3],result[0][0][95][2]-result[0][0][95][0],linewidth=1,edgecolor='r',facecolor='none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn.rpn.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_cls_loc,roi_score,rois,roi_indices = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(target[\"origin_size\"]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(img.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_cls_loc = roi_cls_loc.view(-1, rcnn.head.n_class, 4)\n",
    "# roi = roi.view(-1, 1, 4).expand_as(roi_cls_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rois.view(-1,1,4).expand_as(roi_cls_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1,23]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_cls_loc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rcnn(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_cls_loc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([\n",
    "    [\n",
    "        [\n",
    "            [1,2,3,4,5,6,7,8],\n",
    "            [9,10,11,12,13,14,15,16],\n",
    "            [17,18,19,20,21,22,23,24]\n",
    "        ],\n",
    "        [\n",
    "            [1,2,3,4,5,6,7,8],\n",
    "            [9,10,11,12,13,14,15,16],\n",
    "            [17,18,19,20,21,22,23,24]\n",
    "        ],\n",
    "        [\n",
    "            [1,2,3,4,5,6,7,8],\n",
    "            [9,10,11,12,13,14,15,16],\n",
    "            [17,18,19,20,21,22,23,24]\n",
    "        ]\n",
    "    ]\n",
    "]).view(1,-1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.meshgrid(torch.arange(3),torch.arange(3))[0].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.exp(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1,2,3])*np.array([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "save_path = f\"checkpoints/faster_rcnn_{timestr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
